{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pokemon Grass vs Water vs Fire Classifier","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### Importing libraries and read csv","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras as ks\n\n\nfrom pylab import rcParams\nimport sklearn\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import scale\nfrom collections import Counter\nfrom scipy.stats import pearsonr\n\n\ndef calculate_pvalues(df):\n    df = df.dropna()._get_numeric_data()\n    dfcols = pd.DataFrame(columns=df.columns)\n    pvalues = dfcols.transpose().join(dfcols, how='outer')\n    for r in df.columns:\n        for c in df.columns:\n            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n    return pvalues\n\n\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:52:57.625179Z","iopub.execute_input":"2022-02-08T17:52:57.625809Z","iopub.status.idle":"2022-02-08T17:52:57.634929Z","shell.execute_reply.started":"2022-02-08T17:52:57.625761Z","shell.execute_reply":"2022-02-08T17:52:57.634224Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"\ndf_original = pd.read_csv('../input/pokemon-images-and-types/pokemon.csv')\nprint(df_original.shape)\nprint(df_original.head())\npokemon_names_original_list = df_original['Name'].tolist()\n\n\ndf = pd.read_csv('../input/pokemon-stats/Pokemon stats.csv')\ndf[\"Name\"] = df[\"Name\"].str.lower()\nprint(df.shape)\nprint(df.head())\n\n\ndf = df[df.Name.isin(pokemon_names_original_list)] #removing duplicates (mega evolutions?) and pokemon who didn't exist in the original dataset\nprint(df.shape)\ndf.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:52:57.637525Z","iopub.execute_input":"2022-02-08T17:52:57.638001Z","iopub.status.idle":"2022-02-08T17:52:57.681858Z","shell.execute_reply.started":"2022-02-08T17:52:57.637880Z","shell.execute_reply":"2022-02-08T17:52:57.680903Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### lets sort the pokemons names in order to keep in match with the available image files","metadata":{}},{"cell_type":"code","source":"df = df.sort_values(by=['Name'], ascending=True).reset_index(drop=True) #Sorting by name, alphabetically\nprint(df.head())\n\ndf.dtypes # the types of the different columns\nhp_attack_defense_speed_df = df[[\"HP\", \"Attack\", \"Defense\", \"Speed\"]] #creating a dataframe which contains only hp, attack, defense and speed since they're all numeric and continous (good for linear regression)\nprint(hp_attack_defense_speed_df.head())\n\nprint(hp_attack_defense_speed_df.isnull().sum().sum())# the result is 0 so there are no missing values here\n\n\n\n\nprint(hp_attack_defense_speed_df.corr()) #creating a correlation matrix based on the hp,attack,defense and speed matrix\nprint(calculate_pvalues(hp_attack_defense_speed_df)) #is p-val calculation working?\n\nsns.pairplot(hp_attack_defense_speed_df) # plotting scatterplots that'll visualize the correlation matrix\n\n\n#there is a rather strong correlation between hp&attack, attack&defense\nreg = linear_model.LinearRegression()\nreg.fit(hp_attack_defense_speed_df[[\"HP\", \"Defense\"]],hp_attack_defense_speed_df.Attack)\nprint(reg.coef_) # the coefficients are 0.3816505 , 0.36193765 for hp and defense respectively\nprint(reg.intercept_) #the intercept is 23.14\n\n#predicting attack for an hypothetical pokemon with an hp of 100 and defense of 70:\nprint(reg.predict([[100,70]])) #the predicted attack is 86.64\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:52:57.683712Z","iopub.execute_input":"2022-02-08T17:52:57.684296Z","iopub.status.idle":"2022-02-08T17:53:00.677362Z","shell.execute_reply.started":"2022-02-08T17:52:57.684249Z","shell.execute_reply":"2022-02-08T17:53:00.676318Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"type1 = df['Type1'].tolist()\n#type2 = df['Type2'].tolist() - prob delete\n#typo = type1 + type2 - prob delete\n\nmain_type = type1 #a list with all the main types\n\n\nplt.figure(figsize=(17, 5))\n\nsns.countplot(x=main_type)\nplt.title('Frequencies of main types of Pokemons') \nplt.show() # it seems like water, normal, grass and bug types are the most common main types","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:00.679213Z","iopub.execute_input":"2022-02-08T17:53:00.679731Z","iopub.status.idle":"2022-02-08T17:53:00.923080Z","shell.execute_reply.started":"2022-02-08T17:53:00.679688Z","shell.execute_reply":"2022-02-08T17:53:00.922367Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"main_type_class = df.Type1.value_counts().keys() #the different main classes of pokemons sorted from the most frequent to the least (each class appears once)\nmain_type_freq = df.Type1.value_counts().values # the corresponding frequency of each class \n\n\n#x2 = df.Type2.value_counts().keys() - prob delete\n#y2 = df.Type2.value_counts().values - prob delete\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:00.924393Z","iopub.execute_input":"2022-02-08T17:53:00.924936Z","iopub.status.idle":"2022-02-08T17:53:00.932082Z","shell.execute_reply.started":"2022-02-08T17:53:00.924892Z","shell.execute_reply":"2022-02-08T17:53:00.931301Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"main_type_freq_chart = pd.DataFrame({'main_type_class':main_type_class, 'main_type_freq':main_type_freq})\nmain_type_freq_chart.head()\n#xy2 = pd.DataFrame({'x2':x2, 'y2': y2}) - prob delete\n#xy2.sort_values(by=['x2'],ascending=True, inplace=True) - prob delete","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:00.933518Z","iopub.execute_input":"2022-02-08T17:53:00.933799Z","iopub.status.idle":"2022-02-08T17:53:00.949384Z","shell.execute_reply.started":"2022-02-08T17:53:00.933765Z","shell.execute_reply":"2022-02-08T17:53:00.948502Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/pokemon-images-and-types/images/images/'\nfig,((ax1, ax2, ax3, ax4),(ax5, ax6, ax7, ax8)) = plt.subplots(2, 4, figsize=(12, 10))\nax = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\nfor i in range(8):\n    img = mpimg.imread(path+df['Name'][i**3]+'.png')\n    ax[i].imshow(img)\n    ax[i].set_title(df['Name'][i**3])\n    ax[i].axis('off')\nplt.tight_layout()\nplt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:00.952425Z","iopub.execute_input":"2022-02-08T17:53:00.952813Z","iopub.status.idle":"2022-02-08T17:53:01.470039Z","shell.execute_reply.started":"2022-02-08T17:53:00.952784Z","shell.execute_reply":"2022-02-08T17:53:01.469052Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"### Image Path Dataframe ","metadata":{}},{"cell_type":"code","source":"path='../input/pokemon-images-and-types/images/images/'\nimg_name = sorted(os.listdir('../input/pokemon-images-and-types/images/images/')) # list of all the names, sorted alphabetically\nimg_paths = []\nfor i in img_name:\n       \n    if i[:len(i)-4:] in df[\"Name\"].tolist():\n        img_paths.append(path + i) # a list with all the paths of the different pokemons (again,alphabetically)\nprint(len(img_paths))\n\n\n\n    \n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.472437Z","iopub.execute_input":"2022-02-08T17:53:01.472725Z","iopub.status.idle":"2022-02-08T17:53:01.493148Z","shell.execute_reply.started":"2022-02-08T17:53:01.472696Z","shell.execute_reply":"2022-02-08T17:53:01.492348Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"df['filepath'] = img_paths #adding colomn of path to the spreadsheet (bug - a mismatch between the size of the dataset and the num of images)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.494444Z","iopub.execute_input":"2022-02-08T17:53:01.494693Z","iopub.status.idle":"2022-02-08T17:53:01.499276Z","shell.execute_reply.started":"2022-02-08T17:53:01.494669Z","shell.execute_reply":"2022-02-08T17:53:01.498266Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"\npoke_type = []\ncode = []\n\nfor i in range(df.shape[0]): #iterate over the number of pokemons, generating a vector of pokemon classes and a vector of codes\n    if (df.iloc[i]['Type1']=='Water'):\n        poke_type.append('Water')\n        code.append(1)\n    elif (df.iloc[i]['Type1']=='Normal'):\n        poke_type.append('Normal')\n        code.append(2)\n    elif (df.iloc[i]['Type1']=='Grass'):\n        poke_type.append('Grass')\n        code.append(3)\n    elif (df.iloc[i]['Type1']=='Bug'):\n        poke_type.append('Bug')\n        code.append(4)\n    else:\n        poke_type.append(None)\n        code.append(None)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.500403Z","iopub.execute_input":"2022-02-08T17:53:01.500707Z","iopub.status.idle":"2022-02-08T17:53:01.794643Z","shell.execute_reply.started":"2022-02-08T17:53:01.500669Z","shell.execute_reply":"2022-02-08T17:53:01.793715Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# adding the pokemon type and code vectors to the main spreadsheet\ndf['main_type'] = poke_type\ndf['code'] = code\n# creating a new spreadsheet based on df by removing missing values in type and keeping only the cols code, type, some stats and filepath\n\nnew_df = df.drop(['Type1', 'Type2', 'Name'], axis=1)\nnew_df = new_df[new_df['type']!='NaN']\nnew_df.reset_index(drop=True, inplace=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.796065Z","iopub.execute_input":"2022-02-08T17:53:01.796522Z","iopub.status.idle":"2022-02-08T17:53:01.873913Z","shell.execute_reply.started":"2022-02-08T17:53:01.796470Z","shell.execute_reply":"2022-02-08T17:53:01.872075Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:19.988406Z","iopub.execute_input":"2022-02-08T17:53:19.988762Z","iopub.status.idle":"2022-02-08T17:53:20.006121Z","shell.execute_reply.started":"2022-02-08T17:53:19.988734Z","shell.execute_reply":"2022-02-08T17:53:20.005038Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"#histogram which shows frequencies of the different pokemon types\nsns.countplot(x=new_df.type)\nplt.title('Pokemons going for training')\nplt.ylabel('Number of images')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:23.474540Z","iopub.execute_input":"2022-02-08T17:53:23.475095Z","iopub.status.idle":"2022-02-08T17:53:23.500400Z","shell.execute_reply.started":"2022-02-08T17:53:23.475060Z","shell.execute_reply":"2022-02-08T17:53:23.499150Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    \n    rescale=1./255, \n    rotation_range=40, \n    width_shift_range=0.2, \n    height_shift_range=0.2, \n    shear_range=.2, \n    zoom_range=0.2,\n    horizontal_flip=True, \n    fill_mode='nearest',\n    validation_split=0.1\n)\n\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    new_df, \n    x_col='filepath', y_col='type',\n    target_size=(120, 120), #the pictures all have the same size, 120x120\n    color_mode='rgba', \n    class_mode='categorical', \n    batch_size=32, \n    shuffle=True, \n    seed=1,\n    subset='training'\n)\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n    new_df , x_col='filepath', y_col='type',\n    target_size=(120, 120),\n    color_mode='rgba', \n    class_mode='categorical', \n    batch_size=4, \n    shuffle=True,\n    seed=1, \n    subset='validation'\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.877851Z","iopub.status.idle":"2022-02-08T17:53:01.878343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_sample = train_generator.next()[0]\n\nplt.figure(figsize=(10, 10))\n\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.imshow(image_sample[i, :, :, :])\n    plt.axis('off')\nplt.show()\nimage_sample.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.879255Z","iopub.status.idle":"2022-02-08T17:53:01.879660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"model = ks.models.Sequential()\n\nmodel.add(ks.layers.Dense(4, input_shape=(120, 120, 4)))\n\nmodel.add(ks.layers.Conv2D(64, (7, 7), activation='relu'))\nmodel.add(ks.layers.MaxPooling2D(2, 2))\n#model.add(ks.layers.Dropout(0.2))\n\nmodel.add(ks.layers.Conv2D(128, (7, 7), activation='relu'))\nmodel.add(ks.layers.MaxPooling2D(2, 2))\n#model.add(ks.layers.Dropout(0.2))\n\n\nmodel.add(ks.layers.Conv2D(256, (7, 7), activation='relu'))\nmodel.add(ks.layers.MaxPooling2D(2, 2))\n#model.add(ks.layers.Dropout(0.2))\n\nmodel.add(ks.layers.Conv2D(512, (7, 7), activation='relu'))\nmodel.add(ks.layers.MaxPooling2D(2, 2))\nmodel.add(ks.layers.Dropout(0.2))\n\n\nmodel.add(ks.layers.Flatten())\n\nmodel.add(ks.layers.Dense(1024, activation='relu'))\n\nmodel.add(ks.layers.Dense(3, activation='softmax'))\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.880546Z","iopub.status.idle":"2022-02-08T17:53:01.880993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.881781Z","iopub.status.idle":"2022-02-08T17:53:01.882142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.layers","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.882972Z","iopub.status.idle":"2022-02-08T17:53:01.883380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callback to stop the training when a particular accuarcy is reached","metadata":{}},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('acc')>0.5) and (logs.get('val_acc')>0.5):\n            print('\\n reached 50% accuarcy so stopping training') #chance level in this case is 25%\n            self.model.stop_training = True\ncallbacks = myCallback()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.884156Z","iopub.status.idle":"2022-02-08T17:53:01.884556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator, \n    validation_data=validation_generator,\n    batch_size=20, \n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(), \n        callbacks\n    ]\n    \n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.885515Z","iopub.status.idle":"2022-02-08T17:53:01.885927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('ggplot')\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(6, 5))\n\nplt.plot(epochs, acc, 'r', label='training_accuracy')\nplt.plot(epochs, val_acc, 'b', label='validation_accuracy')\nplt.title('Training and Validation Accuarcy')\nplt.xlabel('-----epochs--->')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure(figsize=(6, 5))\n\nplt.plot(epochs, loss, 'r', label='training_loss')\nplt.plot(epochs, val_loss, 'b', label='validation_loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('----epochs--->')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.886797Z","iopub.status.idle":"2022-02-08T17:53:01.887230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic regression - multiclass classification\n\n#create a list such that each value is a vector which represents a single picture - data\n#we also need to prepare a corresponding list with pokemon main type - target\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ndata_train, data_test, target_train, target_test = train_test_split(data, target,test_size=0.3)\n\nmodel = LogisticRegression()\nmodel.fit(data_train,target_train)\nmodel.score(data_test,target_test)\n\n#predicting:\nplt.matshow(df)\n\n\nimport numpy as np\n    import matplotlib.pyplot as plt\n    import matplotlib.image as mpimg\n    from google.colab import files\n    from scipy import misc #to see image\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LogisticRegression\n\n    from PIL import Image\n    pil_im = Image.open('papa.png')\n    pil_imgray = pil_im.convert('LA')\n\n    img = np.array(list(pil_imgray.getdata(band=0)), float)\n    img.shape = (pil_imgray.size[1], pil_imgray.size[0])\n    plt.imshow(img)\n\n    for eachRow in img:\n      for eachPixel in eachRow:\n          x_test.append(sum(eachPixel)/3.0)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.887977Z","iopub.status.idle":"2022-02-08T17:53:01.888659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:01.889562Z","iopub.status.idle":"2022-02-08T17:53:01.889978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset=['main_type'])","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:38.353009Z","iopub.execute_input":"2022-02-08T17:53:38.353388Z","iopub.status.idle":"2022-02-08T17:53:38.360940Z","shell.execute_reply.started":"2022-02-08T17:53:38.353353Z","shell.execute_reply":"2022-02-08T17:53:38.360031Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T17:53:40.729923Z","iopub.execute_input":"2022-02-08T17:53:40.730282Z","iopub.status.idle":"2022-02-08T17:53:40.749336Z","shell.execute_reply.started":"2022-02-08T17:53:40.730248Z","shell.execute_reply":"2022-02-08T17:53:40.748335Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}